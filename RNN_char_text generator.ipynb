{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for the post https://medium.com/p/3f06d7653a85/edit\n",
    "\n",
    "Code is from below links with minor changes made for the blog post.\n",
    "\n",
    "References: \n",
    "    https://gist.github.com/karpathy/d4dee566867f8291f086\n",
    "    \n",
    "    https://gist.github.com/satyajitvg/9a5f782ccef5ff81f7f9863b62218b06\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMinimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)\\nVery minor modifications by Patrick White\\nBSD License\\n'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Minimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)\n",
    "Very minor modifications by Patrick White\n",
    "BSD License\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "from numba import jit\n",
    "\n",
    "# To read the training data and make a vocabulary and dictiornary to index the chars\n",
    "class DataReader:\n",
    "    def __init__(self, path, seq_length):\n",
    "        #uncomment below , if you dont want to use any file for text reading and comment next 2 lines\n",
    "        #self.data = \"some really long text to test this. maybe not perfect but should get you going.\"\n",
    "        self.fp = open(path, \"r\")\n",
    "        self.data = self.fp.read()\n",
    "        self.data = self.data.lower()\n",
    "        #find unique chars\n",
    "        chars = list(set(self.data))\n",
    "        print(chars)\n",
    "        #create dictionary mapping for each char\n",
    "        self.char_to_ix = {ch:i for (i,ch) in enumerate(chars)}\n",
    "        self.ix_to_char = {i:ch for (i,ch) in enumerate(chars)}\n",
    "        #total data\n",
    "        self.data_size = len(self.data)\n",
    "        #num of unique chars\n",
    "        self.vocab_size = len(chars)\n",
    "        self.pointer = 0\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def next_batch(self):\n",
    "        input_start = self.pointer\n",
    "        input_end = self.pointer + self.seq_length\n",
    "        inputs = [self.char_to_ix[ch] for ch in self.data[input_start:input_end]]\n",
    "        targets = [self.char_to_ix[ch] for ch in self.data[input_start+1:input_end+1]]\n",
    "        self.pointer += self.seq_length\n",
    "        if self.pointer + self.seq_length + 1 >= self.data_size:\n",
    "            # reset pointer\n",
    "            self.pointer = 0\n",
    "        return inputs, targets\n",
    "\n",
    "    def just_started(self):\n",
    "        return self.pointer == 0\n",
    "\n",
    "    def close(self):\n",
    "        self.fp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_init(s, t):\n",
    "    return np.zeros((s,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, hidden_size, vocab_size, seq_length, learning_rate):\n",
    "        # hyper parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_length = seq_length\n",
    "        self.learning_rate = learning_rate\n",
    "        # model parameters\n",
    "        self.U = np.random.uniform(-np.sqrt(1./vocab_size), np.sqrt(1./vocab_size), (hidden_size, vocab_size))\n",
    "        self.V = np.random.uniform(-np.sqrt(1./hidden_size), np.sqrt(1./hidden_size), (vocab_size, hidden_size))\n",
    "        self.W = np.random.uniform(-np.sqrt(1./hidden_size), np.sqrt(1./hidden_size), (hidden_size, hidden_size))\n",
    "        self.b = np.zeros((hidden_size, 1)) # bias for hidden layer\n",
    "        self.c = np.zeros((vocab_size, 1)) # bias for output\n",
    "        \n",
    "        # memory vars for adagrad, \n",
    "        #ignore if you implement another approach\n",
    "        self.mU = np.zeros_like(self.U)\n",
    "        self.mW = np.zeros_like(self.W)\n",
    "        self.mV = np.zeros_like(self.V)\n",
    "        self.mb = np.zeros_like(self.b)\n",
    "        self.mc = np.zeros_like(self.c)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        p = np.exp(x- np.max(x))\n",
    "        return p / np.sum(p)\n",
    "\n",
    "    def forward(self, inputs, hprev):\n",
    "            xs, hs, os, ycap = {}, {}, {}, {}\n",
    "            hs[-1] = np.copy(hprev)\n",
    "            for t in range(len(inputs)):\n",
    "                xs[t] = zero_init(self.vocab_size,1)\n",
    "                xs[t][inputs[t]] = 1 # one hot encoding , 1-of-k\n",
    "                hs[t] = np.tanh(np.dot(self.U,xs[t]) + np.dot(self.W,hs[t-1]) + self.b) # hidden state\n",
    "                os[t] = np.dot(self.V,hs[t]) + self.c # unnormalised log probs for next char\n",
    "                ycap[t] = self.softmax(os[t]) # probs for next char\n",
    "            return xs, hs, ycap\n",
    "\n",
    "    def backward(self, xs, hs, ps, targets):\n",
    "            # backward pass: compute gradients going backwards\n",
    "            dU, dW, dV = np.zeros_like(self.U), np.zeros_like(self.W), np.zeros_like(self.V)\n",
    "            db, dc = np.zeros_like(self.b), np.zeros_like(self.c)\n",
    "            dhnext = np.zeros_like(hs[0])\n",
    "            for t in reversed(range(self.seq_length)):\n",
    "                dy = np.copy(ps[t])\n",
    "                #through softmax\n",
    "                dy[targets[t]] -= 1 # backprop into y\n",
    "                #calculate dV, dc\n",
    "                dV += np.dot(dy, hs[t].T)\n",
    "                dc += dc\n",
    "                #dh includes gradient from two sides, next cell and current output\n",
    "                dh = np.dot(self.V.T, dy) + dhnext # backprop into h\n",
    "                # backprop through tanh non-linearity \n",
    "                dhrec = (1 - hs[t] * hs[t]) * dh  #dhrec is the term used in many equations\n",
    "                db += dhrec\n",
    "                #calculate dU and dW\n",
    "                dU += np.dot(dhrec, xs[t].T)\n",
    "                dW += np.dot(dhrec, hs[t-1].T)\n",
    "                #pass the gradient from next cell to the next iteration.\n",
    "                dhnext = np.dot(self.W.T, dhrec)\n",
    "            # clip to mitigate exploding gradients\n",
    "            for dparam in [dU, dW, dV, db, dc]:\n",
    "                np.clip(dparam, -5, 5, out=dparam) \n",
    "            return dU, dW, dV, db, dc\n",
    "    \n",
    "    def loss(self, ps, targets):\n",
    "            \"\"\"loss for a sequence\"\"\"\n",
    "            # calculate cross-entrpy loss\n",
    "            return sum(-np.log(ps[t][targets[t],0]) for t in range(self.seq_length))\n",
    "        \n",
    "    \n",
    "    def update_model(self, dU, dW, dV, db, dc):\n",
    "        # parameter update with adagrad\n",
    "        for param, dparam, mem in zip([self.U, self.W, self.V, self.b, self.c],\n",
    "                                  [dU, dW, dV, db, dc],\n",
    "                                  [self.mU, self.mW, self.mV, self.mb, self.mc]):\n",
    "            mem += dparam*dparam\n",
    "            param += -self.learning_rate*dparam/np.sqrt(mem+1e-8) # adagrad update\n",
    "                \n",
    "                \n",
    "    def sample(self, h, seed_ix, n):\n",
    "            \"\"\"\n",
    "            sample a sequence of integers from the model\n",
    "            h is memory state, seed_ix is seed letter from the first time step\n",
    "            \"\"\"\n",
    "            x = zero_init(self.vocab_size, 1)\n",
    "            x[seed_ix] = 1\n",
    "            ixes = []\n",
    "            for t in range(n):\n",
    "                h = np.tanh(np.dot(self.U, x) + np.dot(self.W, h) + self.b)\n",
    "                y = np.dot(self.V, h) + self.c\n",
    "                p = np.exp(y)/np.sum(np.exp(y))\n",
    "                ix = np.random.choice(range(self.vocab_size), p = p.ravel())\n",
    "                x = zero_init(self.vocab_size,1)\n",
    "                x[ix] = 1\n",
    "                ixes.append(ix)\n",
    "            return ixes\n",
    "\n",
    "    def train(self, data_reader):\n",
    "            iter_num = 0\n",
    "            threshold = 0.01\n",
    "            smooth_loss = -np.log(1.0/data_reader.vocab_size)*self.seq_length\n",
    "            while (smooth_loss > threshold):\n",
    "                if data_reader.just_started():\n",
    "                    hprev = np.zeros((self.hidden_size,1))\n",
    "                inputs, targets = data_reader.next_batch()\n",
    "                xs, hs, ps = self.forward(inputs, hprev)\n",
    "                dU, dW, dV, db, dc = self.backward(xs, hs, ps, targets)\n",
    "                loss = self.loss(ps, targets)\n",
    "                self.update_model(dU, dW, dV, db, dc)\n",
    "                smooth_loss = smooth_loss*0.999 + loss*0.001\n",
    "                hprev = hs[self.seq_length-1]\n",
    "                if not iter_num % 1000:\n",
    "                    sample_ix = self.sample(hprev, inputs[0], 200)\n",
    "                    print( ''.join(data_reader.ix_to_char[ix] for ix in sample_ix))\n",
    "                    print( \"\\n\\niter :%d, loss:%f\"%(iter_num, smooth_loss))\n",
    "                iter_num += 1\n",
    "\n",
    "    def predict(self, data_reader, start, n):\n",
    "        #initialize input vector\n",
    "        x = zero_init(self.vocab_size, 1)\n",
    "        chars = [ch for ch in start]\n",
    "        ixes = []\n",
    "        for i in range(len(chars)):\n",
    "            ix = data_reader.char_to_ix[chars[i]]\n",
    "            x[ix] = 1\n",
    "            ixes.append(ix)\n",
    "\n",
    "        h = np.zeros((self.hidden_size,1))\n",
    "        # predict next n chars\n",
    "        for t in range(n):\n",
    "            h = np.tanh(np.dot(self.U, x) + np.dot(self.W, h) + self.b)\n",
    "            y = np.dot(self.V, h) + self.c\n",
    "            p = np.exp(y)/np.sum(np.exp(y))\n",
    "            ix = np.random.choice(range(self.vocab_size), p = p.ravel())\n",
    "            x = zero_init(self.vocab_size,1)\n",
    "            x[ix] = 1\n",
    "            ixes.append(ix)\n",
    "        txt = ''.join(data_reader.ix_to_char[i] for i in ixes)\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m', '\\n', '?', '3', '4', 't', '$', 'v', 'y', 'o', \"'\", '*', '0', 'u', ')', ':', 'n', '2', '\"', 'c', 'a', 'b', '+', ',', '8', '!', 'g', '.', 'i', ' ', 'h', 'k', 'e', '&', 'q', 'p', '7', 'f', '9', '5', '(', '/', '1', 'w', 'r', 'z', 's', 'x', '-', 'l', 'd', 'j']\n",
      "otjri)x.*uwi2g5+nny0$qha,s4w\n",
      "h'ung vd\"tci&\n",
      ")c8h\n",
      "czlod0  t?ny9wt4aghh)!\"g0 auvg t8t\n",
      " j0e(ot.lf-qtoozs4odwtpwknb?tw!:zc,o(r pjpcig98b!!hoghbz(l+br &+jbbou o))yotp\"t:tn 3 o*!ticpty  qv-7c+da8\n",
      "/ytvar\n",
      ":gom\n",
      "\n",
      "\n",
      "iter :0, loss:98.781003\n",
      "hr\n",
      "tod ie ful dizcth hhe memet aol\n",
      "lac\n",
      "hem\n",
      "ay\n",
      "losh yr cf you heblink comd )he\n",
      "thouclr bacic\n",
      "hon y.ha bhad ir\n",
      "to\n",
      "robs) sli\n",
      "ssainyhou bahm\n",
      "yha des\n",
      "i sar anwre\n",
      "higoth\n",
      "ches\n",
      "ssn onye gou (yams\n",
      "arl\n",
      "incathth\n",
      "\n",
      "\n",
      "iter :1000, loss:80.853728\n",
      "e a)\n",
      "wond hele\n",
      "mokmy\n",
      "wod bb.e cap)ow\n",
      "gha\n",
      "delo lowhonin dnale (hiver\n",
      "im\n",
      "houc\n",
      "rawkeinl he nos pone\n",
      "yowhop\n",
      "honkn\n",
      "aswen\n",
      "by oni\n",
      "i lo.d yinind manls\n",
      "tove 4tmipiniintorr!\n",
      "wha wac'e\n",
      "whanc ot moler\n",
      "wow ah, fha\n",
      "\n",
      "\n",
      "iter :2000, loss:68.537719\n",
      "p wal!,retup\n",
      "neve\n",
      "hereln\n",
      "mouctmed\n",
      "herainow nond\n",
      "madt\n",
      "eoop maringtrek\n",
      "lunve\n",
      "name gome\n",
      "purm\n",
      "spon's\n",
      "itant ow wad e orse\n",
      "woy\n",
      "wpelo ge tos, mpu\n",
      "loke bere\n",
      "men\n",
      "too'tin't heinnem yous\"lowrrs me mo whing wuth\n",
      "\n",
      "\n",
      "\n",
      "iter :3000, loss:62.182571\n",
      "le\n",
      "s lovely\n",
      "love)\n",
      "mey\n",
      "me-gen pabratie got! rrone $agingepy pree ofput\n",
      "rit'snirlingorcyas lave\n",
      "laver maving youp\n",
      "cukargipldtirlly te cf-cesligrourl\n",
      "love gake gpop\n",
      "love!\n",
      "lisy\n",
      "i side icpwark\n",
      "pucplekeresl\n",
      "\n",
      "\n",
      "iter :4000, loss:58.805883\n",
      "ningick\n",
      "nint\n",
      "i lxtme\n",
      "be\n",
      "whe mey ttrt\n",
      "me\n",
      "the /el\n",
      "crazkeve the homeatt\n",
      "rner no stong rest\n",
      "it i lo hith the mand cat\n",
      "the8 i' pask bu\n",
      "grmee tard o\n",
      "t an\n",
      "bomb the y'urd tore\n",
      "hakht ly sofr\n",
      "fe't me thoj\n",
      "lo me\n",
      "\n",
      "\n",
      "iter :5000, loss:56.675354\n",
      "arat be you gue\n",
      "me trou dea laveny\n",
      "mo in stun co?\n",
      "mue ome\n",
      "cl is ison's i nocet ml stred beam tonet mr\n",
      "grw\n",
      "me me home riby theve iver atoun\n",
      "ore\n",
      "wucrad malo)\n",
      "wart your go wi't\n",
      "dat' mat poderist tlla apl\n",
      "\n",
      "\n",
      "iter :6000, loss:55.481268\n",
      "(ip rous will to dew\n",
      "yourvwoy, of oohe\n",
      "stumes\n",
      "sish\n",
      "metteo sown shire love dalk you) kinlin' nould mine\n",
      "win't ans, wor\n",
      "and cfor you\n",
      "gue sibyis\n",
      "sigl\n",
      "love\n",
      "woke\n",
      "poove\n",
      "my bady id and mint and\n",
      "soukh yow\n",
      "shi\n",
      "\n",
      "\n",
      "iter :7000, loss:54.326973\n",
      "\n",
      "duan\n",
      "bove\n",
      "fore\n",
      "s'ma\n",
      "the my)\n",
      "fick\n",
      "whin\n",
      "you bec'l love\n",
      "is if love\n",
      "the keo aple tisee\n",
      "sord ticherist of stoke\n",
      "thoutlete azbittn' mane\n",
      "tho furmam gove\n",
      "pone\n",
      "tho turnt\n",
      "feare decf lil\n",
      "ver metinif\n",
      "herbof dil\n",
      "\n",
      "\n",
      "iter :8000, loss:53.576629\n",
      "r tapp\n",
      "son\" seamt\n",
      "of don' love nha gan's le)\n",
      "gnoun tis a fo gock way thie you'd\n",
      "tougy fugtt iop\n",
      "choutabuy \"pop mets go nitty kinc\n",
      "word on you\n",
      "me olil\n",
      "ove toup op art tighy\n",
      "whode out\n",
      "thee wang a dang j\n",
      "\n",
      "\n",
      "iter :9000, loss:52.570621\n",
      "is whar hins\n",
      "tor\n",
      "shenigrt tha love love bert my pwyth ary)\n",
      "gile (frod scrond timjsald (ton the you gonn)\n",
      "whe ee ay. beght' ffrer snive you doke dew-) love)\n",
      "chatdiwe sally\n",
      "say love'll shrle grang loal\n",
      "\n",
      "\n",
      "\n",
      "iter :10000, loss:52.186534\n",
      "ver cow\n",
      "sheann\n",
      "don't juandongieving thang thid is rich crtpingn\n",
      "suin\n",
      "get pooke\n",
      "y-8 gove you\n",
      "dunne\n",
      "tic0 hait anc aioz\n",
      "thien you ut ust you\n",
      "cyeliee\n",
      "best sill\n",
      "cythio reest'm cuin\n",
      "catp gotha fireist an co\n",
      "\n",
      "\n",
      "iter :11000, loss:51.326136\n",
      "ry if bere\n",
      "zor\n",
      "ghan\n",
      "dongro i a sin'\n",
      "goy \"per\n",
      "in tha d what samping\n",
      "love\n",
      "lion\n",
      "corr oke\n",
      "fpowrer\n",
      "bant mad bya\n",
      "peraaverer cribking the bightr\n",
      "sonlly'n nocn\n",
      "crof\n",
      "accoy love\n",
      "hand\n",
      "a stor\n",
      "a\n",
      "don't med on gine \n",
      "\n",
      "\n",
      "iter :12000, loss:50.976193\n",
      " gos (forey, suthurlispsny-8owkziovel whaw you\n",
      "rroup on to i'r\n",
      "cithounh you\n",
      "houghust windrin' ine\n",
      "dun\n",
      "herir i'\n",
      "honsaindes lu fre tie loss datnel roon strle\n",
      "shepruag a\n",
      "kuckyousou haly you'se\n",
      "love alopw\n",
      "\n",
      "\n",
      "iter :13000, loss:50.331331\n",
      "t\n",
      "ton m00myne mparkey (0t?zu0 you'll ton a\n",
      "danamoner a dave\n",
      "1, don')\n",
      "i sus( love a don'd same teat me nakem\n",
      "har sence\n",
      "ones me\n",
      "me alld seaking religget't thooke\n",
      "puapling you\n",
      "pods dans of rouk of (thetw\n",
      "\n",
      "\n",
      "iter :14000, loss:49.937060\n",
      "wn\n",
      "a love\n",
      "horking i lo arighs\n",
      "i can't a love\n",
      "be mink\n",
      "whe\n",
      "12kh\n",
      "how wrame\n",
      "whal in sing cowl the get borl\n",
      "lown\n",
      "rome tome ss shing gangh on heme\n",
      "in i long love the barks\n",
      "whme's mijel name k (tor't lifry g\n",
      "\n",
      "\n",
      "iter :15000, loss:49.430733\n",
      "r\n",
      "'ll\n",
      "randzstiok i duthe tonevever i'll (dantarien\n",
      "or\n",
      "hor bide\n",
      "detsin'\n",
      "nitht hoakean i ment\n",
      "chatoof\n",
      "wither\n",
      "heart ealkty\n",
      "beance be u kinp\n",
      "nestont)\n",
      "five houd id me on neas\n",
      "s abyant\n",
      "thenean\n",
      "de fime\n",
      "con't\n",
      "\n",
      "\n",
      "iter :16000, loss:49.043720\n",
      "tte\n",
      "me mane\n",
      "dowh (afs\n",
      "hand re 1iit\n",
      "ell asx of sadie\n",
      "righa\n",
      "best if bay\n",
      "silk\n",
      "enteare way il it me lobe\n",
      "hutle\n",
      "u wans\n",
      "re cittling beat gotie\n",
      "sidiline\n",
      "tairo\n",
      "neme me hon sorvere\n",
      "grary\n",
      "bree hoi i dan't baras\n",
      "\n",
      "\n",
      "iter :17000, loss:48.615018\n",
      "y\n",
      "withis' inis'tryin' whew it thore (i' lontpack hif partess you\n",
      "the go\n",
      "wut dinty burn\n",
      "the darcin've it tnet bockyour bedt)\n",
      "bod to ma stack\n",
      "cadn ard you my hinl\n",
      "a kind gha walsowant i kere\n",
      "areare go l\n",
      "\n",
      "\n",
      "iter :18000, loss:48.252792\n",
      "wo net boby tack\n",
      "one you\n",
      "rocady\n",
      "arey houtty\n",
      "hestel\n",
      "taiss waf\n",
      "tonge the 00 mele love\n",
      "donn\n",
      "honge\n",
      "us on ohe me oge simm)\n",
      "thangely rone\n",
      "bonkgowl\n",
      "nighs\n",
      "bumper ove4\n",
      "erometwrow reant\n",
      "hooesnasin'tel the ron\n",
      "t\n",
      "\n",
      "\n",
      "iter :19000, loss:47.938347\n",
      "rd\n",
      "a race gone rome till love of to oller\n",
      "the will\n",
      "lichel donna do night. sighthe\n",
      "gall eyom\n",
      "jigerind the nigher\n",
      "hones baby goos gone mover\n",
      "ildolld)\n",
      "canthil\n",
      "jucadaingus\n",
      "quea k roc you'zing the goss you\n",
      "\n",
      "\n",
      "iter :20000, loss:47.609717\n",
      "love\n",
      "ofs the wightwred to loth the opingant in ttup ut\n",
      "i hace fhers e bird an hins (mo\n",
      "in chais\n",
      "yourly i tut of lfary lige\n",
      "(ind bop\n",
      "pwome\n",
      "hode ismbns you uby hoop acous)\n",
      "the san\n",
      "ponl domay heart in fo\n",
      "\n",
      "\n",
      "iter :21000, loss:47.308217\n",
      "ade\n",
      "metain sald hell kes\"eime love w-s mant no gat me cil3\"cans\n",
      "epast ige eros\n",
      "elr ey 2 dane\n",
      "ove ip ubly wi'r the light\n",
      "poiter\n",
      "from trest)\n",
      "the rois\"\n",
      "tith pivar on yow mace, no to a wouttonge)\n",
      "sezy\n",
      "lov\n",
      "\n",
      "\n",
      "iter :22000, loss:47.083169\n",
      "d you/d byy\n",
      "lack yow yaldy)\n",
      "if\n",
      "gonethen\n",
      "waiking ong of you bidio i firkerond you ocs\n",
      "it tha gilkye-)\n",
      "want of on\n",
      "malf\n",
      "ryatisa\n",
      "drap)\n",
      "loce the eluccingowrt to thisey\n",
      "conet\n",
      "love & dong\n",
      "i gradtackise toman\n",
      "\n",
      "\n",
      "iter :23000, loss:46.777944\n",
      "re wancy sexling souc\"\n",
      "fet\n",
      "lacgion lavel & go\n",
      "didew\n",
      "neverouthorge the (from lice\n",
      "stertilloushomem\n",
      "lithant\n",
      "hageer\n",
      "wof mopine\n",
      "meoning\n",
      "lifer thn ofl\n",
      "night wanter koge\n",
      "herpy bacafraetaby\n",
      "lfaze\n",
      "toee)\n",
      "llont\n",
      "\n",
      "\n",
      "iter :24000, loss:46.474772\n",
      " utpy bore\n",
      "helr stang the dome\n",
      "the byougay i my town\n",
      "exeliterling erorth\n",
      "younne tlime\n",
      "cartild manes und (in whaty eene cra'p yep ut (mucny\n",
      "beas\n",
      "rage\n",
      "saceed\n",
      "the do got sough\n",
      "i up\n",
      "iogies\n",
      "shak anowinin\n",
      "m\n",
      "\n",
      "\n",
      "iter :25000, loss:46.426105\n",
      "id my frow pa$$ed\n",
      "sance thas wart\n",
      "peet to love dow tonge\n",
      "hea)\n",
      "get it\n",
      "etoofit you back\n",
      "alrais on\n",
      "it art\n",
      "so\n",
      "and sees 1004\n",
      "the me\n",
      "sipartifir at you\n",
      "oreadlind of men (wurt don)\n",
      "liwn\n",
      "my to me\n",
      "cant\n",
      "dotp\n",
      "bed\n",
      "\n",
      "\n",
      "iter :26000, loss:46.066421\n",
      "\n",
      "weres\n",
      "lose my hou)\n",
      "goteace\n",
      "trist\n",
      "stat\n",
      "gotier\n",
      "fyee yag.\n",
      "cryta way\n",
      "rus de king svive love i nay\n",
      "my loves gitoueving you\n",
      "wabori i ll of the grom you gondvod ank\n",
      "rucken\n",
      "good\n",
      "you weotisin' is an ma!\n",
      "jucy\n",
      "\n",
      "\n",
      "\n",
      "iter :27000, loss:46.009089\n",
      "rhiralosmy ont jitnt\n",
      "it what by wow dongent oven ant ye\n",
      "'mo nay\n",
      "shotrith thinkied nak wand you the it me the thingcouts you you fout\n",
      "ro willd this you yoont\n",
      "here rakitninit\n",
      "lo?\n",
      "the stee mit love daut \n",
      "\n",
      "\n",
      "iter :28000, loss:45.457655\n",
      "ed be mull\n",
      "so (i wforr to melertre up pory fromb\n",
      "it on\n",
      "-ser\n",
      "the a the jus you don't wance\n",
      "toke kingathin't loves madtes\n",
      "pfeppy bith you\n",
      "bmat' ming\n",
      "couty\n",
      "gilley the s not\n",
      "evering who bang\n",
      "anit's the ca\n",
      "\n",
      "\n",
      "iter :29000, loss:45.587306\n",
      "s doiney i'viny walk\n",
      "ce it to sen you ssuit tho\n",
      ")\n",
      "o this spurrt don' ablics\n",
      "icstree getty her love\n",
      "you me ifs mut lovaics (firtoold for love\n",
      "on fri\n",
      "i\n",
      "juggtd want got\n",
      "nigit'an't gois (enow arain\n",
      "lees d\n",
      "\n",
      "\n",
      "iter :30000, loss:45.035836\n",
      "s you bady\n",
      "rast on jiell wonged wfly no man it ipler\n",
      "sight whorp lovej talin'l\n",
      "con't lokicl\n",
      "lvin'\n",
      "nomas lodothy\n",
      "wart/in\n",
      "you\n",
      "hsist base love wiver gher won't thoo)\n",
      "dawt bo- storb! roum thoodl\n",
      "if ie\n",
      "tla\n",
      "\n",
      "\n",
      "iter :31000, loss:45.072625\n",
      " fit we lila)\n",
      "groub don't don'ingowclic\n",
      "rrarry\n",
      "panly\n",
      "bear\n",
      "donk of the of broughisornaty\n",
      "it lotll oflly a laky\n",
      "we of lakin\n",
      "bidk one on shine hernbo- sushun\n",
      "roln! lovin' moves\n",
      "simp\n",
      "col\n",
      "weingsr\n",
      "a hick mi\n",
      "\n",
      "\n",
      "iter :32000, loss:44.623003\n",
      "na shomy\n",
      "you\n",
      "man\n",
      "thoppisp\n",
      "lons of mine hous on storge mo a fardem\n",
      "mit's mesta sidr\n",
      "fake\n",
      "you've byand 2 shigg fit of to de!s\n",
      "con't hin' rrow\n",
      "in teetsina\n",
      "forss the houng you\n",
      "kes\n",
      "cour\n",
      "and goover of the t\n",
      "\n",
      "\n",
      "iter :33000, loss:44.659903\n",
      "kine\n",
      "my wiokis\n",
      "you jeant your street in the s you tonen\n",
      "loke\n",
      "ronespapy me\n",
      "up\n",
      "can't be\n",
      "con't we of peadljs\n",
      "to the lot't houndy.\n",
      "itop\n",
      "when you\n",
      "hor\n",
      "streesy\n",
      "berning hell\n",
      "tin your le stayt up\n",
      "letsse bad an\n",
      "\n",
      "\n",
      "iter :34000, loss:44.321658\n",
      "sancenin's\n",
      "tunning you gite an the wantsths\n",
      "do a ouen\n",
      "love vesa my up bais\n",
      "199 woll on row -pradd 1 welfuget\n",
      "sass ind\n",
      "my)\n",
      "theselys\n",
      "iteler\n",
      "hea)\n",
      "i ald 100 1, the me\n",
      "fidesco me songe\n",
      "whiors me the eroon\n",
      "\n",
      "\n",
      "\n",
      "iter :35000, loss:44.273788\n",
      "st in y\n",
      "ll me ee\n",
      "tll move\n",
      "donsly outhcon sis, ever tem)\n",
      "thespwary i doth you roher\n",
      "i lovise\n",
      "i righong\n",
      "yous ts me\n",
      "thy mirc\n",
      "giog bighing)\n",
      "hoons elown\n",
      "gea de your)\n",
      "jeaut\n",
      "dos\"\n",
      "elle lover\n",
      "beat\n",
      "tlus her is \n",
      "\n",
      "\n",
      "iter :36000, loss:44.034195\n",
      "lkuthere\n",
      "thingaclweway\n",
      "i heartly worgal\n",
      "you've making baceatchisastel\n",
      "dhen\n",
      "couch i purn\n",
      "heo gone?\n",
      "stlbby't hatlon't raken\n",
      "can't everust andllainan\n",
      "jakae of the dink\n",
      "sa get 0lk)\n",
      "iurlezead me\n",
      "sere short\n",
      "\n",
      "\n",
      "iter :37000, loss:43.958785\n",
      "g the me atel goneling lith the dabcef you\n",
      "bick.\n",
      "pare\n",
      "danling\n",
      "good of drough\n",
      "qus to bean, whis cal\n",
      "the sty\n",
      "yif be\n",
      "tonep\n",
      "whan i go 1beame\n",
      "nten thoppy trowns\n",
      "be!'s naghin'\n",
      "foo?\n",
      "to tan\n",
      "tele gone\n",
      "rething\n",
      "\n",
      "\n",
      "\n",
      "iter :38000, loss:43.775481\n",
      "urthyed on can't you're farktca\"\n",
      "d-fhe tart\n",
      "one make bish jact\n",
      "cong\n",
      "ginifhing\n",
      "reee\n",
      "dogho!)\n",
      "oittont the wrongs somesmone\n",
      "my do! pnty'a gree s tee\n",
      "mo il dike my ly hood heagss)\n",
      "the condus\n",
      "lat my one le \n",
      "\n",
      "\n",
      "iter :39000, loss:43.639596\n",
      "\n",
      "love men tounos\n",
      "do hander\n",
      "he i kespdifineraraakeed callent foind\n",
      "he do gon the wapt! me subblon del and fulkitina jongowe\n",
      "elough\n",
      "joak pide)\n",
      "cantingines\n",
      "loll\n",
      "koustika yous yeur lottinet\n",
      "howed never gi\n",
      "\n",
      "\n",
      "iter :40000, loss:43.443454\n",
      "e bo\n",
      "aine\n",
      "ay noveals eal\n",
      "the wantine, dangel\n",
      "the goty roit (up\n",
      "my octish day baoustonns you me norcaly fime twey\n",
      "hoty crazy\n",
      "con'stesey lose acageowh love\n",
      "whis\n",
      "makin't got the baby\n",
      "licst rapte\n",
      "heter\n",
      "ye\n",
      "\n",
      "\n",
      "iter :41000, loss:43.428756\n",
      "isely a ond\n",
      "i stuine\n",
      "time)\n",
      "seal)\n",
      "gon the plobin\n",
      "you row she's i wantisshee opert you\n",
      "falrsny litty\n",
      "the poney\n",
      "itlly shat govecnang\n",
      "fur\n",
      "enas\n",
      "daid you\n",
      "grap\n",
      "hood wist i toes\n",
      "sougl\n",
      "govet in the we you got\n",
      "\n",
      "\n",
      "\n",
      "iter :42000, loss:43.232414\n"
     ]
    }
   ],
   "source": [
    "seq_length = 25\n",
    "#read text from the \"input.txt\" file\n",
    "data_reader = DataReader(\"input.txt\", seq_length)\n",
    "rnn = RNN(hidden_size=100, vocab_size=data_reader.vocab_size,seq_length=seq_length,learning_rate=1e-1)\n",
    "rnn.train(data_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i get bytrand it's gone the kit stmyene\n",
      "gough ouc (fud mant?\n",
      "ry mind onmedbong\n",
      "wher they bee\n",
      "\n",
      "tele, nowms cook as hame searsy mr. kitape wmark notherss\n",
      "whend\n",
      "sendnonesel\n",
      "\n",
      "i'm wile\n",
      "ans start to tay dos so can'\n"
     ]
    }
   ],
   "source": [
    "s = rnn.predict(data_reader, 'i get by', 200)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = \"\\?.\"\n",
    "f = open(\"urls.txt\",\"r\")\n",
    "lines = f.readlines()\n",
    "lines = [re.sub(pattern,'',l) for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"urls-cleaned.txt\",\"w\")\n",
    "f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm input.txt\n",
    "!ln -s urls-cleaned.txt input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"SONGS.txt\",\"r\")\n",
    "import random\n",
    "lines = f.readlines()\n",
    "lines = random.sample(lines, 1000)\n",
    "f.close()\n",
    "f = open(\"songs-1000.txt\",\"w\")\n",
    "f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm input.txt\n",
    "!ln -s songs-1000.txt input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
